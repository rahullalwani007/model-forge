# ğŸ“ EduVision 2026 â€” Classroom Crowd Detection & Student Counting

[![Live Demo](https://img.shields.io/badge/ğŸš€_Live_Demo-Gradio-orange?style=for-the-badge)](https://6648f1f78220c70e48.gradio.live)
[![YOLOv8](https://img.shields.io/badge/Model-YOLOv8s_+_YOLOv8m-blue?style=for-the-badge)](https://github.com/ultralytics/ultralytics)
[![Python](https://img.shields.io/badge/Python-3.10+-green?style=for-the-badge)](https://python.org)
[![Kaggle](https://img.shields.io/badge/Trained_On-Kaggle_T4_GPU-20BEFF?style=for-the-badge)](https://kaggle.com)

> **ğŸ† Hackathon Submission â€” Team GSM | February 25, 2026**
>
> AI-powered system that detects and counts students in real-world classroom CCTV images using YOLOv8 with WBF ensemble and automated threshold tuning.

---

## ğŸ¯ Live Demo

**ğŸ‘‰ [Try it now: https://6648f1f78220c70e48.gradio.live](https://6648f1f78220c70e48.gradio.live)**

Upload any classroom image â†’ Get instant bounding box detections + student count.

![demo](https://img.shields.io/badge/Status-LIVE-brightgreen?style=flat-square)

---

## ğŸ“¸ Sample Results

| Input (Classroom CCTV) | Output (Detected Students) |
|:---:|:---:|
| Raw classroom image with 20+ students | Green bounding boxes with confidence scores |
| Varying angles, lighting, occlusions | Accurate count overlay on image |

---

## ğŸ§  Problem Statement

> **EduVision 2026**: Build a fully automated system that detects all people in classroom images (bounding boxes) and accurately estimates the student count per image.

### Evaluation Criteria
| Metric | Weight | Our Score |
|:---|:---:|:---:|
| **mAP@0.5** (Detection) | 50% | **0.9471** |
| **MAE** (Counting Error) | 50% | **0.3231** |
| Precision | â€” | 0.9256 |
| Recall | â€” | 0.9246 |

### Key Challenges
- ğŸ« Dense classrooms with 5â€“50+ students per image
- ğŸ‘¥ Heavy occlusion (students overlapping behind desks)
- ğŸ“· CCTV angles with perspective distortion
- ğŸ’¡ Varying lighting conditions (daylight, fluorescent, shadows)
- ğŸª‘ Furniture noise (chairs, desks, monitors)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EduVision 2026 Pipeline                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  CSV Annotations â”€â”€â†’ YOLO Format â”€â”€â†’ Train YOLOv8s (50ep)  â”‚
â”‚  (xmin,ymin,xmax,ymax)  (cx,cy,w,h)     â†“                  â”‚
â”‚                                     Train YOLOv8m (50ep)    â”‚
â”‚                                          â†“                  â”‚
â”‚                                   Threshold Tuning          â”‚
â”‚                                   (conf + IoU sweep)        â”‚
â”‚                                          â†“                  â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                              â”‚   WBF Ensemble + TTA  â”‚       â”‚
â”‚                              â”‚  (2 models Ã— 2 flips) â”‚       â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                          â†“                  â”‚
â”‚                                   Size Filtering            â”‚
â”‚                                          â†“                  â”‚
â”‚                              Bounding Boxes + Count         â”‚
â”‚                                          â†“                  â”‚
â”‚                              CSV + JSON + Gradio Demo       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Details

| Component | Details |
|:---|:---|
| **Primary Model** | YOLOv8s (11.2M params) â€” Fast, accurate, trains in ~45min on T4 |
| **Secondary Model** | YOLOv8m (25.9M params) â€” Higher capacity for ensemble boost |
| **Ensemble** | Weighted Boxes Fusion (WBF) with IoU=0.55 |
| **TTA** | Horizontal flip augmentation at inference |
| **Pretrained** | COCO weights (includes robust "person" detection) |
| **Fine-tuned On** | 4,236 classroom CCTV images |

---

## ğŸ“Š Dataset

| Property | Value |
|:---|:---|
| **Source** | EduVision 2026 Hackathon (Kaggle) |
| **Total Images** | 4,236 |
| **Train / Val Split** | 3,812 / 424 (90/10) |
| **Annotation Format** | CSV (`filename, width, height, class, xmin, ymin, xmax, ymax`) |
| **Classes** | `Person` (1 class) |
| **Avg People/Image** | ~25 |
| **Image Size** | 640Ã—640 px |
| **Challenges** | Occlusion, CCTV angles, lighting variation, furniture noise |

---

## ğŸ› ï¸ Training Configuration

| Parameter | YOLOv8s (Primary) | YOLOv8m (Ensemble) |
|:---|:---:|:---:|
| Epochs | 50 | 20 |
| Image Size | 640 | 640 |
| Batch Size | 16 | 8 |
| Optimizer | AdamW (lr=0.001) | SGD (lr=0.01) |
| Early Stopping | 15 epochs patience | 15 epochs patience |
| GPU | NVIDIA T4 | NVIDIA T4 |

### Augmentation Pipeline

| Augmentation | Value | Rationale |
|:---|:---:|:---|
| Mosaic | 1.0 | Multi-scale student detection |
| Mixup | 0.15 | Handle overlapping/occluded students |
| Copy-Paste | 0.1 | Increase instance density |
| HSV (H/S/V) | 0.015/0.7/0.4 | Lighting robustness |
| Scale | 0.5 | Different camera distances |
| Degrees | 10Â° | Tilted camera angles |
| Horizontal Flip | 0.5 | Directional invariance |

---

## ğŸ¯ Post-Processing

1. **Confidence Threshold**: `0.35` (tuned on validation set to minimize MAE)
2. **NMS IoU Threshold**: `0.45` (prevents double-counting in dense seating)
3. **WBF Ensemble**: Merges 4 prediction sets (2 models Ã— 2 TTA flips)
4. **Size Filtering**: Removes boxes < 3% image height (noise) or > 95% (background)
5. **Student Count**: Direct count of all filtered detections

---

## ğŸ“ Project Structure

```
EduVision-2026/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ setup_and_eda.py                   # Step 1: Dataset exploration & analysis
â”œâ”€â”€ convert_to_yolo.py                 # Step 2: CSV â†’ YOLO format conversion
â”œâ”€â”€ train_model.py                     # Step 3: Train YOLOv8s + YOLOv8m
â”œâ”€â”€ evaluate_and_tune.py               # Step 4: Threshold tuning on validation
â”œâ”€â”€ inference_and_submission.py         # Step 5: Generate predictions
â”œâ”€â”€ visualize_results.py               # Step 6: Create visualizations
â”œâ”€â”€ technical_report_generator.py      # Step 7: Auto-generate technical report
â”œâ”€â”€ gradio_app.py                      # Step 8: Live Gradio demo
â”œâ”€â”€ quick_demo.py                      # Fallback: Static demo image generator
â”œâ”€â”€ prep_test_today.py                 # Pre-hackathon environment validator
â”‚
â”œâ”€â”€ submission/
â”‚   â”œâ”€â”€ count_predictions.csv          # Per-image student count (for MAE)
â”‚   â”œâ”€â”€ detection_predictions.json     # COCO-format bounding boxes (for mAP)
â”‚   â”œâ”€â”€ technical_report.md            # Generated technical report
â”‚   â”œâ”€â”€ demo/
â”‚   â”‚   â””â”€â”€ demo_grid.png             # Static demo visualization
â”‚   â””â”€â”€ visualizations/
â”‚       â””â”€â”€ sample_predictions.png     # Prediction grid
â”‚
â””â”€â”€ runs/
    â”œâ”€â”€ yolov8s_eduvision/weights/best.pt   # Primary model weights
    â””â”€â”€ yolov8m_eduvision/weights/best.pt   # Ensemble model weights
```

---

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
pip install ultralytics ensemble-boxes pycocotools albumentations gradio scikit-learn scipy supervision
```

### 2. Full Pipeline (Hackathon Execution Order)

```bash
# Step 1: Explore the dataset
python setup_and_eda.py

# Step 2: Convert CSV annotations to YOLO format
python convert_to_yolo.py

# Step 3: Train models (YOLOv8s primary + YOLOv8m if time permits)
python train_model.py

# Step 4: Tune confidence & IoU thresholds on validation set
python evaluate_and_tune.py

# Step 5: Run inference and generate submission files
python inference_and_submission.py

# Step 6: Create result visualizations
python visualize_results.py

# Step 7: Auto-generate technical report
python technical_report_generator.py

# Step 8: Launch live Gradio demo
python gradio_app.py
```

### 3. Inference Only (Using Pre-trained Weights)

```python
from ultralytics import YOLO

model = YOLO("runs/yolov8s_eduvision/weights/best.pt")
results = model("classroom_image.jpg", conf=0.35, iou=0.45)

# Count people
count = sum(len(r.boxes) for r in results)
print(f"Students detected: {count}")

# Visualize
for r in results:
    annotated = r.plot()
```

---

## ğŸ”‘ Key Design Decisions

### Why YOLOv8?
- **Speed**: YOLOv8s trains in ~45 min on T4 â€” critical for a 5-hour hackathon
- **Accuracy**: State-of-the-art mAP on person detection
- **COCO Pretrained**: Already understands "person" class from 330K images
- **Ecosystem**: Stable NMS, easy WBF integration, Gradio-compatible

### Why Ensemble?
- WBF fusion of YOLOv8s + YOLOv8m reduces false positives by cross-validating predictions
- TTA (horizontal flip) catches students missed due to asymmetric occlusion
- Net result: **Lower MAE** with minimal computational overhead

### Safety-First Architecture
- YOLOv8s trained **first** â†’ guarantees a submission even if time runs out
- **Time-Check algorithm** auto-decides whether to train YOLOv8m based on remaining hackathon minutes
- Config chain (JSON files) automatically passes tuned parameters between scripts â€” zero manual copying

### Automated Threshold Tuning
- Exhaustive grid search over `conf âˆˆ [0.10, 0.50]` and `iou âˆˆ [0.30, 0.60]`
- Optimized directly for **MAE** (the competition counting metric)
- Best found: `conf=0.35, iou=0.45`

---

## ğŸ“ˆ Results Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric                 â”‚ Score    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ mAP@0.5               â”‚ 0.9471   â”‚
â”‚ mAP@0.5:0.95          â”‚ 0.7743   â”‚
â”‚ Precision              â”‚ 0.9256   â”‚
â”‚ Recall                 â”‚ 0.9246   â”‚
â”‚ Counting MAE           â”‚ 0.3231   â”‚
â”‚ Avg Inference Time     â”‚ ~15ms    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒ Live Demo

**ğŸ”— [https://6648f1f78220c70e48.gradio.live](https://6648f1f78220c70e48.gradio.live)**

Features:
- ğŸ“· Upload any classroom image
- ğŸŸ¢ Green bounding boxes around detected people
- ğŸ‘¥ Real-time student count
- ğŸšï¸ Adjustable confidence & IoU sliders
- ğŸ“Š Detailed detection report per image
- ğŸ“ Pre-loaded example images from the dataset

---

## ğŸ‘¥ Team

**Team GSM** â€” EduVision 2026 Hackathon

---

## ğŸ“œ License

This project was built for the **EduVision 2026 Hackathon**. All code is provided for educational and competition purposes.

---

## ğŸ™ Acknowledgements

- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) â€” Object detection framework
- [Weighted Boxes Fusion](https://github.com/ZFTurbo/Weighted-Boxes-Fusion) â€” Ensemble method
- [Gradio](https://gradio.app/) â€” Live demo UI
- [Kaggle](https://kaggle.com) â€” GPU compute & dataset hosting
- EduVision 2026 organizers for the dataset and problem statement

---

<p align="center">
  <b>Built with â¤ï¸ during EduVision 2026 Hackathon</b><br>
  <i>From raw CCTV images to real-time student counting in 5 hours</i>
</p>
